{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"ClassifyAnything Part 1: Preprocessing\"\n",
    "author: \"Joseph Chao-Chung Kuo (ckuo@ukaachen.de)\"\n",
    "date: today\n",
    "output:\n",
    "  general:\n",
    "    output_stdout: false\n",
    "    output_error: false\n",
    "    output: true\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    toc-depth: 3\n",
    "    html-math-method: katex\n",
    "    code-fold: true\n",
    "    code-tools: true\n",
    "    number_sections: true\n",
    "    embed-resources: true\n",
    "    page-layout: full\n",
    "execute:\n",
    "    echo: true\n",
    "    warning: false\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Supervised learning for classification_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "import plotly.figure_factory as ff\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster import hierarchy\n",
    "from IPython.display import display\n",
    "# Set notebook mode to work in offline\n",
    "pyo.init_notebook_mode()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load the dataset\n",
    "\n",
    "#### 1.1.1 Matrix with observations and features (X)\n",
    "\n",
    "In scikit-learn, when working with supervised classification tasks, the typical convention is to represent your data in a DataFrame or array-like structure where each row represents an observation (sample) and each column represents a feature (attribute). However, because genomic data usually have way more features (genes) than observations (samples), we use features as rows and observations as columns.\n",
    "\n",
    "Please load the file and make it into the format as:\n",
    "- features as rows\n",
    "- observations as columns\n",
    "- all row index and column names should be unique.\n",
    "- all values in the dataframe should be numerical. All metadata should be cleaned.\n",
    "\n",
    "Please edit the codes below for loading your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the matrix with observation as columns and features (X) as rows\n",
    "input_path = \"/data/projects/240814_Popzhelyazkova_Bremer_Neuropathologie_DNAmArray/analysis/DNAmArray/processed_mVals.csv\"\n",
    "data = pd.read_csv(input_path, sep=\",\", index_col=0)\n",
    "# data.drop(columns=['gene_id'], inplace=True)\n",
    "# data = data.groupby('').mean()\n",
    "print(data.shape)\n",
    "print(\"#### Data index ####\")\n",
    "print(data.index[0:5])\n",
    "print(\"#### Data columns ####\")\n",
    "print(data.columns[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to extract a subset of the data for a test run, please use the codes below.\n",
    "# This line should be commented out for training the real model.\n",
    "# data = data.head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = data.isnull().sum()\n",
    "display(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide on the method to handle missing values\n",
    "# For example, let's fill missing values with the mean of the column\n",
    "# data = data.fillna(data.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3 Check the rows with all zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = len(data[(data == 0).all(axis=1)])\n",
    "print(\"Number of rows with all zeros: \"+str(count))\n",
    "if count > 0:\n",
    "    data = data[~(data == 0).all(axis=1)]\n",
    "    print(str(count)+\" rows are removed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4. Identify outliers using z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = np.abs((data - data.mean()) / data.std())\n",
    "outliers = (z_scores > 3).sum().sort_values(ascending=False)\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide on the approach to handle outliers\n",
    "# For example, let's remove rows with outliers\n",
    "data = data[(z_scores <= 10).all(axis=1)]\n",
    "print(data.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4 Load labels (y)\n",
    "\n",
    "Please make sure the observation names are consistent to the column names in the above matrix (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the named Series with labels (y) as the content and the observation names as names\n",
    "# labels_path = \"inputs/test_labels.csv\"\n",
    "# labels = pd.read_csv(labels_path, sep=\"\\t\", index_col=0).squeeze()\n",
    "labels = pd.DataFrame(data=data.columns, columns=[\"label\"])\n",
    "labels[['Group', 'sample']] = labels['label'].str.split('.', n=1, expand=True)\n",
    "# print(\"#### Labels ####\")\n",
    "# print(labels.iloc[0:5])\n",
    "display(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether all row names are unique\n",
    "if data.index.duplicated().any():\n",
    "    print(\"Row names are not unique.\")\n",
    "# Check whether all column names are unique\n",
    "if data.columns.duplicated().any():\n",
    "    print(\"Column names are not unique.\")\n",
    "# Check whether there is any non-numeric values in data\n",
    "is_numeric = pd.to_numeric(data.stack(), errors='coerce').notnull().all()\n",
    "if not is_numeric:\n",
    "    print(\"Some values are not numeric.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = ['ALS',  'Control',  'IBM',  'Multiminicores',  'NMA',  'PM']\n",
    "labels = labels[labels['Group'].isin(keep)]\n",
    "data = data[labels[\"label\"].tolist()]\n",
    "set(labels[\"Group\"].tolist())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Explore the dataset\n",
    "\n",
    "This section is for understanding your dataset statistically and visually."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(data.info())\n",
    "# print(data.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Process the data for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data into log10 scale for further visualization\n",
    "data_viz = data\n",
    "# data_viz = data_viz.reset_index()\n",
    "data_long = pd.melt(data_viz, id_vars=data_viz.columns[0], var_name='sample', value_name='mVal')\n",
    "# Merging data long table with labels (y)\n",
    "data_long = pd.merge(data_long, labels, left_on='sample', right_on=\"sample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to reduce dimensionality to 3 components\n",
    "pca = PCA(n_components=3)\n",
    "pca_data = pca.fit_transform(data_viz.transpose())\n",
    "pca_data = pd.DataFrame(pca_data)\n",
    "pca_data.columns = [\"PC 1\", \"PC 2\", \"PC 3\"]\n",
    "pca_data[\"sample\"] = data_viz.columns\n",
    "pca_data = pd.merge(pca_data, labels, left_on='sample', right_on=\"label\")\n",
    "fig = px.scatter_3d(pca_data, x='PC 1', y='PC 2', z='PC 3', color='Group', hover_name=\"label\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a box plot using Seaborn\n",
    "sns.boxplot(data=data_viz,\n",
    "            flierprops={'marker': 'o', 'markerfacecolor': 'gray',\n",
    "                        'markersize': 2, 'alpha': 0.3})\n",
    "# Set the title and labels\n",
    "# plt.title('Box Plot')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('M Value')\n",
    "# Hide x-axis tick labels\n",
    "plt.xticks([])\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Save variables for next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'outputs'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "# Save variables to a file\n",
    "with open('outputs/01_Variables.pkl', 'wb') as file:\n",
    "    pickle.dump((data, labels), file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
